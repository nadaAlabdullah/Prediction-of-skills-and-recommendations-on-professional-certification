{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ffecdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web Secraping from Bayt.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11202b93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\1853523566.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\1853523566.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Browser Invoked successfully\n",
      "Finished\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = \"C:\\\\Program Files\\\\Google\\Chrome\\\\Application\\\\chrome.exe\" \n",
    "driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "print(\"Chrome Browser Invoked successfully\")\n",
    "#Job site link\n",
    "url = \"https://www.bayt.com/en/saudi-arabia/jobs/information-technology-jobs/\"\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "npo_jobs = {}\n",
    "job_no = 0\n",
    "attempt = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    driver.current_url\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    jobs = soup.find_all(\"li\", class_ = \"has-pointer-d\")\n",
    "    \n",
    "    for job in jobs:\n",
    "        title = job.find(\"h2\", class_ = \"jb-title m0 t-large\").text\n",
    "        date = job.find(\"div\", class_ = \"jb-date col p0x t-xsmall t-mute\").text\n",
    "        URL = job.find(\"h2\", class_ = \"jb-title m0 t-large\").a[\"href\"]\n",
    "        \n",
    "        job_no += 1\n",
    "        npo_jobs[job_no] = [title.strip(), date.strip(), \"https://www.bayt.com\" + URL]\n",
    "        \n",
    "        #data you need collection\n",
    "        #print(f'''\n",
    "        #Job Name: {title.strip()}\n",
    "        #date: {date.strip()}\n",
    "        #Link: {\"https://www.bayt.com\" + URL}\n",
    "        #''')\n",
    "        \n",
    "\n",
    "    if job_no <= 2700: #number of Ads\n",
    "            print(\"Finished\")\n",
    "            break  \n",
    "    try:\n",
    "        element =  driver.find_element(By.XPATH, \"//*[@id='pagination']/li[6]/a\")\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except StaleElementReferenceException:\n",
    "        if attempt == 3:\n",
    "            raise\n",
    "        attempt += 1\n",
    "    \n",
    "df = pd.DataFrame.from_dict(npo_jobs, orient = \"index\", columns = [\"Job Name\", \"Date\", \"Link\"]) \n",
    "df.to_excel(\"Bayt_Data_final.xlsx\")\n",
    "print(\"done\")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42800e0",
   "metadata": {},
   "source": [
    "# Web Secraping from Wadhefa.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897ee75d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\2605141633.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\2605141633.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Browser Invoked successfully\n",
      "Finished\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException ,NoSuchElementException\n",
    "\n",
    "options = Options()\n",
    "#chrome_options = Options()\n",
    "options.binary_location = \"C:\\\\Program Files\\\\Google\\Chrome\\\\Application\\\\chrome.exe\" \n",
    "driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "print(\"Chrome Browser Invoked successfully\")\n",
    "\n",
    "#Job site link    \n",
    "url = \"https://www.wadhefa.com/jobfind.php?action=search&jids%5B%5D=75&lids%5B%5D=000&kwd=&cmdSearch=Search\"\n",
    "if \"english/\" not in url:\n",
    "    url = url.replace(\"https://www.wadhefa.com/\", \"https://www.wadhefa.com/english/\")\n",
    "    \n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "\n",
    "Titles = []\n",
    "Dates  = []\n",
    "Links  = []\n",
    "\n",
    "attempt = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    driver.current_url\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "    \n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        #print(tds)\n",
    "        tds_ = tr.find(\"td\")\n",
    "        date = tds_.find_next_sibling(\"td\").text\n",
    "        Dates.append(date)\n",
    "        \n",
    "        for td in tds:\n",
    "            if td.find('a'):\n",
    "                link = td.find('a')['href']\n",
    "                if \"job\" in link:\n",
    "                    link = td.find('a')['href']\n",
    "                    Links.append(link)\n",
    "                    URL = Links\n",
    "                    \n",
    "                    title = td.find('a').text\n",
    "                    Titles.append(title)\n",
    "        #data you need collection        \n",
    "        #print(f'''\n",
    "         #Job Name: {title}\n",
    "         #Date: {date}\n",
    "         #Link: {link}\n",
    "         #''')\n",
    "       \n",
    "    \n",
    "    if len(URL) >= 490: #number of Ads\n",
    "            print(\"Finished\")\n",
    "            break\n",
    "    \n",
    "    try:\n",
    "        element =  driver.find_element(By.LINK_TEXT, \"Next »\")\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except StaleElementReferenceException:\n",
    "        if attempt == 3:\n",
    "            raise\n",
    "        attempt += 1\n",
    "                    \n",
    "driver.quit()\n",
    "\n",
    "d = {\"Job Name\" : Titles, \"Date\" : Dates, \"Link\" : URL}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.index += 1 #start index at 1\n",
    "df.to_excel(\"files\\Wadhefa_Data_fina1.xlsx\")\n",
    "\n",
    "print(\"done\")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffede0f-9367-4ba6-a2d9-fa6477d8b8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\3371648696.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\3371648696.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Browser Invoked successfully\n",
      "Finished\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException ,NoSuchElementException\n",
    "\n",
    "options = Options()\n",
    "\n",
    "options.binary_location = \"C:\\\\Program Files\\\\Google\\Chrome\\\\Application\\\\chrome.exe\" \n",
    "driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "print(\"Chrome Browser Invoked successfully\")\n",
    "#Job site link      \n",
    "url = \"https://www.wadhefa.com/jobfind.php?action=search&jids%5B0%5D=76&lids%5B0%5D=000&kwd=&cmdSearch=Search\"\n",
    "if \"english/\" not in url:\n",
    "    url = url.replace(\"https://www.wadhefa.com/\", \"https://www.wadhefa.com/english/\")\n",
    "    \n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "\n",
    "Titles = []\n",
    "Dates  = []\n",
    "Links  = []\n",
    "\n",
    "attempt = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    driver.current_url\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "    \n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        #print(tds)\n",
    "        tds_ = tr.find(\"td\")\n",
    "        date = tds_.find_next_sibling(\"td\").text\n",
    "        Dates.append(date)\n",
    "        \n",
    "        for td in tds:\n",
    "            if td.find('a'):\n",
    "                link = td.find('a')['href']\n",
    "                if \"job\" in link:\n",
    "                    link = td.find('a')['href']\n",
    "                    Links.append(link)\n",
    "                    URL = Links\n",
    "                    \n",
    "                    title = td.find('a').text\n",
    "                    Titles.append(title)\n",
    "        #data you need collection        \n",
    "        #print(f'''\n",
    "         #Job Name: {title}\n",
    "         #Date: {date}\n",
    "         #Link: {link}\n",
    "         #''')\n",
    "       \n",
    "    \n",
    "    if len(URL) >= 970: #number of jobs\n",
    "            print(\"Finished\")\n",
    "            break\n",
    "    \n",
    "    try:\n",
    "        element =  driver.find_element(By.LINK_TEXT, \"Next »\")\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except StaleElementReferenceException:\n",
    "        if attempt == 3:\n",
    "            raise\n",
    "        attempt += 1\n",
    "                    \n",
    "driver.quit()\n",
    "\n",
    "d2 = {\"Job Name\" : Titles, \"Date\" : Dates, \"Link\" : URL}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "df2.index += 1 #start index at 1\n",
    "df2.to_excel(\"files\\Wadhefa_Data_fina2.xlsx\")\n",
    "\n",
    "print(\"done\")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444196b1-dd25-498a-a2b7-ea731a6c3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\871799530.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_332\\871799530.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Browser Invoked successfully\n",
      "Finished\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException ,NoSuchElementException\n",
    "\n",
    "options = Options()\n",
    "#chrome_options = Options()\n",
    "options.binary_location = \"C:\\\\Program Files\\\\Google\\Chrome\\\\Application\\\\chrome.exe\" \n",
    "driver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Users\\a\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "print(\"Chrome Browser Invoked successfully\")\n",
    "#Job site link      \n",
    "url = \"https://www.wadhefa.com/jobfind.php?action=search&jids%5B0%5D=84&lids%5B0%5D=000&kwd=&cmdSearch=Search\"\n",
    "if \"english/\" not in url:\n",
    "    url = url.replace(\"https://www.wadhefa.com/\", \"https://www.wadhefa.com/english/\")\n",
    "    \n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "\n",
    "Titles = []\n",
    "Dates  = []\n",
    "Links  = []\n",
    "\n",
    "attempt = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    driver.current_url\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_ = \"tablelist job-list\")\n",
    "    \n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        #print(tds)\n",
    "        tds_ = tr.find(\"td\")\n",
    "        date = tds_.find_next_sibling(\"td\").text\n",
    "        Dates.append(date)\n",
    "        \n",
    "        for td in tds:\n",
    "            if td.find('a'):\n",
    "                link = td.find('a')['href']\n",
    "                if \"job\" in link:\n",
    "                    link = td.find('a')['href']\n",
    "                    Links.append(link)\n",
    "                    URL = Links\n",
    "                    \n",
    "                    title = td.find('a').text\n",
    "                    Titles.append(title)\n",
    "        #data you need collection        \n",
    "        #print(f'''\n",
    "         #Job Name: {title}\n",
    "         #Date: {date}\n",
    "         #Link: {link}\n",
    "         #''')\n",
    "       \n",
    "    \n",
    "    if len(URL) >= 222: #number of jobs\n",
    "            print(\"Finished\")\n",
    "            break\n",
    "    \n",
    "    try:\n",
    "        element =  driver.find_element(By.LINK_TEXT, \"Next »\")\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except StaleElementReferenceException:\n",
    "        if attempt == 3:\n",
    "            raise\n",
    "        attempt += 1\n",
    "                    \n",
    "driver.quit()\n",
    "\n",
    "d3 = {\"Job Name\" : Titles, \"Date\" : Dates, \"Link\" : URL}\n",
    "df3 = pd.DataFrame(data=d3)\n",
    "df3.index += 1 #start index at 1\n",
    "df3.to_excel(\"files\\Wadhefa_Data_fina3.xlsx\")\n",
    "\n",
    "print(\"done\")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb5a0f2-973d-4ba7-b8ac-99d0fc509c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                           Job Name        Date  \\\n",
      "0           1  Information technology technician  04/20/2023   \n",
      "1           2       Sales and Marketing Engineer  04/19/2023   \n",
      "2           3                      IT technician  04/18/2023   \n",
      "3           4              Network administrator  04/12/2023   \n",
      "4           5                   Network Engineer  04/10/2023   \n",
      "\n",
      "                                                Link  \n",
      "0  https://www.wadhefa.com/english/details/job/71...  \n",
      "1  https://www.wadhefa.com/english/details/job/71...  \n",
      "2  https://www.wadhefa.com/english/details/job/71...  \n",
      "3  https://www.wadhefa.com/english/details/job/71...  \n",
      "4  https://www.wadhefa.com/english/details/job/71...  \n",
      "------------------------\n",
      "   Unnamed: 0                     Job Name        Date  \\\n",
      "0           1            Web/SQL Developer  04/17/2023   \n",
      "1           2       Database Administrator  04/17/2023   \n",
      "2           3  UX User Experience Designer  04/13/2023   \n",
      "3           4                IT Specialist  04/11/2023   \n",
      "4           5  Computer marketing engineer  04/10/2023   \n",
      "\n",
      "                                                Link  \n",
      "0  https://www.wadhefa.com/english/details/job/71...  \n",
      "1  https://www.wadhefa.com/english/details/job/71...  \n",
      "2  https://www.wadhefa.com/english/details/job/71...  \n",
      "3  https://www.wadhefa.com/english/details/job/71...  \n",
      "4  https://www.wadhefa.com/english/details/job/71...  \n",
      "------------------------\n",
      "   Unnamed: 0                                  Job Name        Date  \\\n",
      "0           1                           CCTV technician  04/18/2023   \n",
      "1           2                             Sales Manager  04/15/2023   \n",
      "2           3                          Network Engineer  04/12/2023   \n",
      "3           4  Computer engineer - cooperative training  04/10/2023   \n",
      "4           5                        network technician  04/10/2023   \n",
      "\n",
      "                                                Link  \n",
      "0  https://www.wadhefa.com/english/details/job/71...  \n",
      "1  https://www.wadhefa.com/english/details/job/71...  \n",
      "2  https://www.wadhefa.com/english/details/job/71...  \n",
      "3  https://www.wadhefa.com/english/details/job/71...  \n",
      "4  https://www.wadhefa.com/english/details/job/71...  \n",
      "------------------------\n",
      "   Unnamed: 0                           Job Name        Date  \\\n",
      "0           1  Information technology technician  04/20/2023   \n",
      "1           2       Sales and Marketing Engineer  04/19/2023   \n",
      "2           3                      IT technician  04/18/2023   \n",
      "3           4              Network administrator  04/12/2023   \n",
      "4           5                   Network Engineer  04/10/2023   \n",
      "\n",
      "                                                Link  \n",
      "0  https://www.wadhefa.com/english/details/job/71...  \n",
      "1  https://www.wadhefa.com/english/details/job/71...  \n",
      "2  https://www.wadhefa.com/english/details/job/71...  \n",
      "3  https://www.wadhefa.com/english/details/job/71...  \n",
      "4  https://www.wadhefa.com/english/details/job/71...  \n",
      "------------------------\n",
      "                            Job Name        Date  \\\n",
      "0  Information technology technician  04/20/2023   \n",
      "1       Sales and Marketing Engineer  04/19/2023   \n",
      "2                      IT technician  04/18/2023   \n",
      "3              Network administrator  04/12/2023   \n",
      "4                   Network Engineer  04/10/2023   \n",
      "\n",
      "                                                Link  \n",
      "0  https://www.wadhefa.com/english/details/job/71...  \n",
      "1  https://www.wadhefa.com/english/details/job/71...  \n",
      "2  https://www.wadhefa.com/english/details/job/71...  \n",
      "3  https://www.wadhefa.com/english/details/job/71...  \n",
      "4  https://www.wadhefa.com/english/details/job/71...  \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"Wadhefa_Data_fina1.xlsx\")\n",
    "print(df.head()) \n",
    "print(\"------------------------\")\n",
    "\n",
    "df2 = pd.read_excel(\"Wadhefa_Data_fina2.xlsx\")\n",
    "print(df2.head())\n",
    "print(\"------------------------\")\n",
    "\n",
    "df3 = pd.read_excel(\"Wadhefa_Data_fina3.xlsx\")\n",
    "print(df3.head())\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "df4=pd.concat([df,df2,df3])\n",
    "print(df4.head())\n",
    "print(\"------------------------\")\n",
    "\n",
    "df4.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "print(df4.head())\n",
    "df4.to_excel(\"Wadhefa_Data_final.xlsx\")\n",
    "df4\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dfa41-d61c-4162-bb41-c7017a8f3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
